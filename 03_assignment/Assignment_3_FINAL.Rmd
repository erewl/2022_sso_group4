---
title: "Assignment_3_Group_4"
author: "Katrin Grunert, Carmen Byrne Salsas, Bono Lardinois"
date: "10/23/2022"
output:
  word_document: default
  pdf_document: default
  html_document: default
---

# Statistics, Simulation & Optimization: Assignment 3

## 3.1 Single-Machine Scheduling

### 3.1.a
To solve this single-machine scheduling problem, an integer linear optimization model was created by using PULP. With this model, the most optimal solution was found to complete all ten jobs with the least amount of tardiness. The model has the following decision variables. 

* jobs: the names of jobs available
* d_i: duration of a certain job
* r_i: release time of a certain job in hours
* t_i: due date of a certain job
* n: number of jobs
* y_i_j: decision variable, with y_i_j = 1 if job i goes before before job j
* z_i: tardiness of each job

The model also made use of the following constraints.

1. No overlap: 
  x~i~ + d~i~ <= x~j~ + 1000 * y~i,j~ (for each i, j. As long i is not j)
2. Job order: 
  y~i,j~ + y~j,i~ = 1 (for each i, j. As long i is not j)
3. release date: 
  x~i~ >= r~i~ (for each i)
4. Start and duration times not greater than the due date (tardiness):
  x~i~ + d~i~ - t~i~ <= z~i~, z~i~~ >= 0 (for each i)
5. Binary decision variable:
  $y_{i,j} \in 0,1$, (for all i and j. As long i is not j)

i and j are the number of jobs with a possible integer value of 1 to 10. 

To calculate the optimal solution to this problem:
$$\sum_{n=1}^{10} c_i * z_i$$
Here c~i~ is 1, and z~i~ is the tardiness of a job.

After running the model, this gave the following optimal schedule:

| Job order       | 6 | 7 | 9 | 1 | 2 | 3  | 5  | 4  | 8  | 10 |
|-----------------|---|---|---|---|---|----|----|----|----|----|
| Start time (x_i) | 0 | 1 | 1 | 3 | 7 | 12 | 15 | 22 | 27 | 30 |
| Tardiness (z_i)  | 0 | 0 | 0 | 0 | 0 | 0  | 2  | 2  | 0  | 20 |

In this schedule, we start with job 6 and end with job 10. Tasks 5, 4, and 10 will have tardiness with a total of 24 hours. This means that the optimal schedule the machines need an extra 24 hours in order to complete all the jobs.


### 3.1.b
Compared to the problem in exercise, a few things need to change to model the optimal solution. Now Jobs 1, 3, 4, 6, and 10 require a sieve of type 1, whereas jobs 2, 5, 7, 8, and 9 require a sieve of type 2. When jobs come after each other with a different sieve, the extra time it costs to change the sieve is 1 hour. The constraints in this problem were modified with an extra binary decision variable: costs~i,j~. This variable will be 1 if the jobs require a different sieve. Moreover, the constraint of preventing overlap was modified to implement the cost variable correctly. The new no-overlap constraint is now:
$$x_{i} + d_{i} + cost_{i} <= x{j} + 1000 * y_{i.j}$$
With this new constraint, the 1 hour of extra time will be added if jobs x~i~ and x~j~ are not in the same groups. This gave a result of a total tardiness of 40 hours. The table with the optimal schedule is presented below:

| Job order       | 9 | 7 | 6 | 1 | 3 | 2  | 5  | 8  | 4  | 10 |
|-----------------|---|---|---|---|---|----|----|----|----|----|
| Start time (xi) | 0 | 2 | 3 | 4 | 8 | 12 | 17 | 24 | 28 | 33 |
| Tardiness (zi)  | 0 | 0 | 0 | 0 | 0 | 5  | 4  | 0  | 8  | 23 |

Compared to the previous schedule, we see a different order and a delay for the following jobs: 6, 2, 4. This means there will be a change of sieve three times. This has changed the order of the most optimized solution and brings 16 additional hours compared to the first schedule without the extra costs of sieve change.


## 3.2 Project Planning

### Exercise 3.2.a

The project consists out of 7 activities (1,2,3,4,5,6,7) which all have a respective expected duration $d_i = [1,3,2,3,4,5,2], i \in [1,2,3,4,5,6,7]$ 

Their finish times $FT_i$ are formulated according to the dependencies depicted in the assignment description as follows:

1. $FT_1 = d_1$
1. $FT_2 = d_1 + d_2$
1. $FT_3 = d_1 + d_3$
1. $FT_4 = d_1  + d_4$
1. $FT_5 = max(d_2,d_3) + d_5$
1. $FT_6 = max(d_3 + d_4) + d_6$
1. $FT_7 = max(d_5, d_6) + d_7$


The activity durations follow an exponential distribution $r(x) = e^{-d_ix}$ and therefore the function  $x = \frac{-ln(u)}{\frac{1}{d_i}}$ was used to simulate new values for each activity, where $u$ is a random sample from a uniform distribution.

This was done 10,000 times in Excel, and the sample average (expected project finish time) was 14.081.

### Exercise 3.2.b

Next, we calculate a 95% confidence interval using the sample standard deviation of 6.167, the z-score of 1.96, and the sample size of 10,000.

We can say with 95% confidence that the expected finish time lies between the lower and upper bounds of [13.85, 14.09]

### Exercise 3.2.c

The probability that the project takes more than 12 days can be represented as a sample proportion $p$. Therefore we count the occurrences where the finishing time is greater than 12 in our 10,000 samples and divide that by the total number of samples.

Doing so, the sample proportion is 0.581.

Knowing the sample proportion, we can construct the 95% confidence interval using the sample standard deviation of 0.494, the z-score of 1.96, and the sample size of 10,000.

With 95% confidence, we can say that the probability for the expected finishing time to be greater than 12 is between the lower and upper bounds of [0.571, 0,591].

## 3.3 Optimal Hotel Prizes

### 3.3.a
We calculated the probability parameter of the demand distribution (p_sucess) based on the formula 0.9 - price/300 where the price ranges from 100 to 180 euro. Then, we simulated the revenue for each price 100000 times using the excel formula MIN(10, BINOM.INV(n_trials, p_sucess, RAND())) * price. In this formula, n_trials is equal to 20 according to the parameters of the demand probability distribution. The inverse binomial distribution of the demand returns how many rooms were demanded in that simulation round. We take the minimum between the demand and 10 because only 10 rooms can be occupied. Finally we multiply the number of demanded rooms by their price to calculate the revenue.


We then calculated 95% confidence intervals for the mean revenue for each price using the student t-distribution, the sample average and the sample standard deviation. At a significance level of 0.05 and with 100000-1 degrees of freedom, the t critical value is approximately equal to 1.96. We obtained the following confidence intervals:

|Price       | 100 | 110 | 120 | 130 | 140 | 150  | 160  | 170  | 180 |
|-----------------|---|---|---|---|---|----|----|----|----|----|
|Mean | 963.10 | 1035.33 | 1094.06 | 1135.85 | 1161.62 | 1169.70 | 1154.40 | 1124.76 | 1076.41 |
|95% Confidence interval  | [793.71, 1132.48] | [801.12, 1269.54] | [785.09, 1403.03] | [746.09, 1525.61] | [693.97, 1629.28] | [626.64, 1712.76]  | [542.94, 1765.86]  | [460.80, 1788.73]  | [372.61, 1780.21]  |
|Confidence interval width | 338.78 | 468.42 | 617.94 | 779.52 | 935.31 | 1086.12  | 1222.93  | 1327.94  | 1407.60  |


From this table it would seem that the best price is 150€ since it yields the highest mean revenue (1169.70€); however, the confidence intervals grow wider as the prices increase which raises the doubt as to whether 150€ is significantly better than the lower prices. 

In order to address this question we performed pairwise t-tests using Sidak's correction for the significance level. There are 9 possible prices; hence, for a given price $\pi$, and every other price $\pi$' we will test the following hypotheses:\

H0: $\pi$ is better than $\pi$'\
H1: $\pi$ is not better than $\pi$' \

Given an original significance level $\alpha$ of 0.05, the corrected significance level $\alpha$' is $1- (1-\alpha)^{1/(9-1)}$, which is approximately equal to 0.00369.

Let $\mu$ and $s$ be the mean revenue and its sample standard deviation for a price $\pi$ ($\mu$' and $s$' for price $\pi$'). The corrected hypotheses become then:
H0: $\mu >  \mu' - \beta   \frac{\sqrt{s^2 + s'^2}}{\sqrt{n}}$ \
H1: $\mu \leq  \mu' - \beta   \frac{\sqrt{s^2 + s'^2}}{\sqrt{n}}$, \

where $n$ is equal to the number of simulations per price (100000), and beta is equal to the inverse t-distribution at $1-\alpha'$ with $n-1$ degrees of freedom (calculated using the following expression in excel: T.INV(1-0.00369, 100000-1)), namely 2.49.

The only price for which the null hypothesis was not rejected was 150€, meaning that 150€ is the optimal price to maximize the revenue in this problem at a 0.05 significance level.


### 3.3.b

In order to implement the "ranking and selection option 2" algorithm we simulated revenues using the same excel commands as in part 3.3.a. The main difference is that we had a total  budget of 900 simulations to split between 9 prices for the first rounds of simulations; hence, $n$ is equal to 100 (i.e., 900/100).

We then performed pairwise t-tests as explained in part 3.3.a; the main difference is that 
$\beta$ is equal to the inverse t-distribution at $1-\alpha'$ with $100-1$ degrees of freedom; namely, 2.54.

The hypotheses are similar to those in part 3.3.a.; namely: \
H0: $\mu >  \mu' - \beta   \frac{\sqrt{s^2 + s'^2}}{\sqrt{n}}$ \
H1: $\mu \leq  \mu' - \beta   \frac{\sqrt{s^2 + s'^2}}{\sqrt{n}}$.\

For this set of prices {130, 140, 150, 160, 170} the null hypothesis could not be rejected when compared to every other price (from the set {100, 110, ..., 180}). 
Hence, 5 prices moved on to the next round of simulations. The remaining simulation budget was 9100; hence, the revenue was simulated 1820 (i.e., 9100/5) times for each price.

At a significance level of 0.05 and with 1820-1 degrees of freedom, the t critical value is approximately equal to 1.96. We obtained the following confidence intervals:

|Price       | 130 | 140 | 150  | 160  | 170 |
|-----------------|---|---|----|----|----|----|
|Mean | 1138.71 | 1158.85 | 1163.82 | 1156.57 | 1124.06 |
|95% Confidence interval | [755.40, 1522.03] | [686.81, 1630.88] | [614.29, 1713.35] | [549.12, 1764.02] | [459.12, 1788.99]  |
|Confidence interval width  | 766.62 | 944.07 | 1099.06 | 1214.89 | 1329.88 |

Thus, with this method the price that achieves the largest mean revenue (1163.82€) is also 150€; hence, 150€ is the optimal price in order to maximize the revenue which agrees with our answer from part 3.3.a.


## Appendix
![Fig 1: Screenshot of Python code (Exercise 3.1 A)](3_1_a.png)

![Fig 2: Screenshot of Python code (Exercise 3.1 B)](3_1_b.png)

![Fig 3: Screenshot of Excel sheet (Exercise 3.3 A)](3_3_a.png)

![Fig 4: Screenshot of Excel sheet (Exercise 3.3 B Step 2)](3_3_b_step2.png)

![Fig 5: Screenshot of Excel sheet (Exercise 3.3 B Step 4)](3_3_b_step4.png)

